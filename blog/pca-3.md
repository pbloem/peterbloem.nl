---
title: A friendly introduction to Principal Component Analysis
date: 31-01-2020
math: true
code: true
---
<!-- {% raw %} -->

<header>
<h1>A friendly introduction to PCA</h1>
<div class="subh1">part 3: The singular value decomposition</div>
</header>

<ul class="links">
	<li>31 Jan 2020</li>
	<li><a href="https://github.com/pbloem/blog/blob/master/2020/pca.ipynb">notebook on github</a></li>
		<li><a href="/blog/pca">part 1</a></li>
		<li><a href="/blog/pca-2">part 2</a></li>
</ul>

## The Singular Value Decomposition

##  Summary, and clean up

### Three perspectives on PCA

* Reconstruction loss
** one point of reference in the space of solutions to the combined problem
* Variance maximization

### Mean centering

### Non-linear PCA

### Other PCAs

### PCA in a Deep Learning World

 * PCA is a tradeoff between simplicity and power. This makes it much better for analysis than deep nonlinear methods.
 * PCA works on wide data.
-- conclusion
--- fast, hands-free and most importantly interpretable. Analysis (ref Antske?)

<!-- {% endraw %} -->